{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "QXCLsaMlKsqU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1abb5c29-1979-4050-ebd7-cb2cc7b2f1a6",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:37:30.061456Z",
     "start_time": "2025-04-23T17:37:30.054096Z"
    }
   },
   "source": [
    "\n",
    "#!pip install gradio pandas --quiet\n",
    "#!pip install gradio SpeechRecognition --quiet\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# import gradio as gr\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import speech_recognition as sr\n",
    "\n",
    "\n",
    "# # Dummy placeholder for data insight functions\n",
    "# def initialize_data_insights():\n",
    "#     return \"Profile Summary Initialized\", \"Anomalies Initialized\"\n",
    "\n",
    "# def insight_agent_interactive(user_query, profile_summary, anomalies):\n",
    "#     response = f\"Insight response to: {user_query}\"\n",
    "#     return response, profile_summary, anomalies\n",
    "\n",
    "# # Upload Handler\n",
    "# # def explore_data(files):\n",
    "#     results = []\n",
    "#     if len(files) == 0:\n",
    "#         return \"Please upload at least one CSV file.\", \"\", \"\", \"\"\n",
    "\n",
    "#     for file in files:\n",
    "#         df = pd.read_csv(file.name)\n",
    "\n",
    "#         head = f\" `{file.name}`\\n\" + df.head().to_markdown()\n",
    "#         summary = df.describe().to_markdown()\n",
    "\n",
    "#         info_buf = io.StringIO()\n",
    "#         df.info(buf=info_buf)\n",
    "#         info = info_buf.getvalue()\n",
    "\n",
    "#         results.append((head, summary, info))\n",
    "\n",
    "#     all_preview = \"\\n\\n---\\n\\n\".join([r[0] for r in results])\n",
    "#     all_summary = \"\\n\\n---\\n\\n\".join([r[1] for r in results])\n",
    "#     all_info = \"\\n\\n---\\n\\n\".join([r[2] for r in results])\n",
    "\n",
    "#     return \" Upload successful!\", all_preview, all_summary, all_info\n",
    "\n",
    "# # Chatbot Logic\n",
    "# def chatbot_response(message, history):\n",
    "#     response = \" I'm still learning!\"\n",
    "#     return response, history + [(message, response)]\n",
    "\n",
    "# # Speech-to-text\n",
    "# def speech_to_text(audio_file):\n",
    "#     recognizer = sr.Recognizer()\n",
    "#     with sr.AudioFile(audio_file) as source:\n",
    "#         audio_data = recognizer.record(source)\n",
    "#     try:\n",
    "#         return recognizer.recognize_google(audio_data)\n",
    "#     except sr.UnknownValueError:\n",
    "#         return \"Sorry, I couldn't understand that.\"\n",
    "\n",
    "# # Insight agent handler\n",
    "# def launch_insight_agent(user_query, profile_summary, anomalies):\n",
    "#     if profile_summary is None or anomalies is None:\n",
    "#         profile_summary, anomalies = initialize_data_insights()\n",
    "\n",
    "#     response, profile_summary, anomalies = insight_agent_interactive(\n",
    "#         user_query, profile_summary, anomalies\n",
    "#     )\n",
    "#     return response, profile_summary, anomalies\n",
    "\n",
    "# # Gradio App\n",
    "# with gr.Blocks() as app:\n",
    "#     gr.Markdown(\" Data Dashboard\")\n",
    "#     gr.Markdown(\"Get to Know about your data Data Dashboard\")\n",
    "\n",
    "\n",
    "#     with gr.Tab(\"Upload + Explore\"):\n",
    "#         file_input = gr.File(file_types=[\".csv\"], file_count=\"multiple\", label=\"Upload CSV files\")\n",
    "#         status = gr.Textbox(label=\"Status\")\n",
    "#         preview = gr.Markdown(label=\" Data Preview\")\n",
    "#         summary = gr.Markdown(label=\"Summary Statistics\")\n",
    "#         info = gr.Textbox(label=\" Data Info\", lines=15)\n",
    "\n",
    "#         file_input.change(fn=explore_data, inputs=file_input, outputs=[status, preview, summary, info])\n",
    "\n",
    "#     with gr.Tab(\" Non-agentic Chatbot\"):\n",
    "#         gr.Markdown(\"Speak to your data (voice-to-text + chatbot)\")\n",
    "#         transcript = gr.Textbox(label=\" Transcript\")\n",
    "#         chatbot = gr.ChatInterface(fn=chatbot_response, textbox=transcript)\n",
    "#         mic = gr.Microphone(label=\" Speak here\")\n",
    "#         mic.change(fn=speech_to_text, inputs=mic, outputs=transcript)\n",
    "\n",
    "#     with gr.Tab(\" Data Insight Agent\"):\n",
    "#         with gr.Row():\n",
    "#             user_input = gr.Textbox(label=\"Ask about your dataset\")\n",
    "#         with gr.Row():\n",
    "#             output = gr.Textbox(label=\"Insight Response\", lines=20)\n",
    "#         mic = gr.Microphone(label=\" Speak here\")\n",
    "#         mic.change(fn=speech_to_text, inputs=mic, outputs=transcript)\n",
    "\n",
    "#         profile_summary = gr.State(value=None)\n",
    "#         anomalies = gr.State(value=None)\n",
    "#         submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "#         submit_btn.click(\n",
    "#             fn=launch_insight_agent,\n",
    "#             inputs=[user_input, profile_summary, anomalies],\n",
    "#             outputs=[output, profile_summary, anomalies]\n",
    "#         )\n",
    "\n",
    "# app.launch(share=True)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "NjlDciUrtVaT",
    "outputId": "2e63a0d7-fc53-433e-c9f0-ee218695227a",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:37:30.084490Z",
     "start_time": "2025-04-23T17:37:30.073483Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:42.415120Z",
     "start_time": "2025-04-23T17:37:30.455684Z"
    }
   },
   "cell_type": "code",
   "source": "from backend import *",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ key loaded: True\n",
      "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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:55: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", **best_cfg)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(s, errors=\"coerce\", **kwargs)\n",
      "C:\\Users\\DELL\\PycharmProjects\\DataQuestHackathon\\insight_env\\DataCleaning.py:196: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  return data.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== auto_visualize logs ===\n",
      "(no errors)\n",
      "\n",
      "=== custom_plot(hist) logs ===\n",
      "Plot saved to ./reports\\bmi_None_hist.png\n",
      "\n",
      "\n",
      "=== custom_plot(scatter) logs ===\n",
      "Plot saved to ./reports\\bmi_target_scatter.png\n",
      "\n",
      "\n",
      "=== All accumulated logs ===\n",
      "   DataVisualizerAssistant initialized.\n",
      "   [AUTO] Auto-detecting columns...\n",
      "   [AUTO] Using columns: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
      "   Correlation Heatmap saved to ./reports\\correlation_heatmap.png\n",
      "   Distribution - age saved to ./reports\\distplot_age.png\n",
      "   Distribution - sex saved to ./reports\\distplot_sex.png\n",
      "   Distribution - bmi saved to ./reports\\distplot_bmi.png\n",
      "   Distribution - bp saved to ./reports\\distplot_bp.png\n",
      "   Distribution - s1 saved to ./reports\\distplot_s1.png\n",
      "   Distribution - s2 saved to ./reports\\distplot_s2.png\n",
      "   Distribution - s3 saved to ./reports\\distplot_s3.png\n",
      "   Distribution - s4 saved to ./reports\\distplot_s4.png\n",
      "   Distribution - s5 saved to ./reports\\distplot_s5.png\n",
      "   Distribution - s6 saved to ./reports\\distplot_s6.png\n",
      "   Distribution - target saved to ./reports\\distplot_target.png\n",
      "   Plot saved to ./reports\\bmi_None_hist.png\n",
      "   Plot saved to ./reports\\bmi_target_scatter.png\n",
      "\n",
      "=== Generated plot files ===\n",
      "   ./reports\\correlation_heatmap.png\n",
      "   ./reports\\distplot_age.png\n",
      "   ./reports\\distplot_sex.png\n",
      "   ./reports\\distplot_bmi.png\n",
      "   ./reports\\distplot_bp.png\n",
      "   ./reports\\distplot_s1.png\n",
      "   ./reports\\distplot_s2.png\n",
      "   ./reports\\distplot_s3.png\n",
      "   ./reports\\distplot_s4.png\n",
      "   ./reports\\distplot_s5.png\n",
      "   ./reports\\distplot_s6.png\n",
      "   ./reports\\distplot_target.png\n",
      "   ./reports\\bmi_None_hist.png\n",
      "   ./reports\\bmi_target_scatter.png\n",
      "{'num_rows': 2633521, 'num_columns': 8, 'types_of_data': {'object': ['event_time', 'category_code', 'brand'], 'int64': ['order_id', 'product_id'], 'float64': ['category_id', 'price', 'user_id']}, 'missing_or_unusual': {'category_id': {'missing_values': 431954}, 'category_code': {'missing_values': 612202}, 'brand': {'missing_values': 506005}, 'price': {'missing_values': 431954}, 'user_id': {'missing_values': 2069352}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded and ready!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "#  Enhance insight with relevant emojis\n",
    "def enhance_with_emojis(insight):\n",
    "    insight = insight.strip()\n",
    "    if \"%\" in insight:\n",
    "        insight += \" 🔢\"\n",
    "    if \"increase\" in insight or \"growth\" in insight or \"higher\" in insight:\n",
    "        insight += \" 📈\"\n",
    "    elif \"decrease\" in insight or \"drop\" in insight or \"lower\" in insight:\n",
    "        insight += \" 📉\"\n",
    "    else:\n",
    "        insight += \" 🔍\"\n",
    "    return insight\n",
    "\n",
    "# Generate LinkedIn-style post\n",
    "def generate_linkedin_post(insight):\n",
    "    enhanced = enhance_with_emojis(insight)\n",
    "\n",
    "    templates = [\n",
    "        \"🚀 Big news! {insight} Let’s keep pushing! 💪 #DataDriven #Growth\",\n",
    "        \"💡 Insight: {insight} 🔍 Powering smart decisions! #Analytics #Insights\",\n",
    "        \"📊 Did you know? {insight} Let’s scale smarter! 📈 #BusinessIntelligence\",\n",
    "        \"📣 Quick Stat: {insight} 📌 Stay tuned! #Trends #Tech\",\n",
    "    ]\n",
    "\n",
    "    template = random.choice(templates)\n",
    "    return template.format(insight=enhanced)\n",
    "\n",
    "#  Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"##  Auto-LinkedIn Post Generator\")\n",
    "    gr.Markdown(\"Enter your insight and generate a shareable LinkedIn-style summary \")\n",
    "\n",
    "    with gr.Row():\n",
    "        input_text = gr.Textbox(placeholder=\"e.g., Sales increased by 15% this quarter\", label=\"Enter Insight\")\n",
    "\n",
    "\n",
    "\n",
    "    generate_btn = gr.Button(\" Generate Post\")\n",
    "    output_text = gr.Textbox(label=\"💬 LinkedIn-style Post\", lines=4)\n",
    "\n",
    "    generate_btn.click(fn=generate_linkedin_post, inputs=input_text, outputs=output_text)\n",
    "\n",
    "demo.launch()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "BOsmDBem4sSG",
    "outputId": "75076b75-6d62-4c03-bca2-1328c19772e9",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.071360Z",
     "start_time": "2025-04-23T17:38:42.484782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install gradio SpeechRecognition langchain openai transformers spacy\n",
    "#!python -m spacy download en_core_web_sm\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOLhBcx8KQef",
    "outputId": "7850599e-1eca-43d8-f0c9-3ce495a27d99",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.144891Z",
     "start_time": "2025-04-23T17:38:48.139006Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install langchain-experimental\n",
    "#!pip install pyttsx3\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "from backend import process_query, initialize_data_insights, insight_agent_interactive, initialize_agent\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5Z0o7eQBK1lw",
    "outputId": "6072780c-c1ca-4a84-fa79-c641f6ceb985",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.240474Z",
     "start_time": "2025-04-23T17:38:48.230770Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def summary(data):\n",
    "    shape = data.shape\n",
    "    columns = data.columns\n",
    "    missing_values = data.isnull().sum()\n",
    "    summary = f\"A dataset summary includes stats like mean, median, mode, and data distribution. \\n\" \\\n",
    "              f\"Shape: {shape} \\n\" \\\n",
    "              f\"Columns: {columns} \\n\" \\\n",
    "              f\"Missing Values: {missing_values}\"\n",
    "    return summary"
   ],
   "metadata": {
    "id": "PGyxxC-itB3h",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.299723Z",
     "start_time": "2025-04-23T17:38:48.289013Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def insights():\n",
    "    return \"Insights might include trends, patterns, and anomalies found in the dataset.\"\n"
   ],
   "metadata": {
    "id": "r_PByncew7NR",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.348742Z",
     "start_time": "2025-04-23T17:38:48.341648Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def data_cleaning(method):\n",
    "    cleaned_df = dataCleanPipeLine(df, method)\n",
    "    print(method)\n",
    "    cleaned_df.to_csv(\"cleaned_dataset.csv\", index=False)\n",
    "    return \"✅ Data cleaned successfully! Columns fixed, duplicates dropped, missing values handled.\"\n"
   ],
   "metadata": {
    "id": "mJpODOLdxBdZ",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.396984Z",
     "start_time": "2025-04-23T17:38:48.387058Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# import gradio as gr\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import speech_recognition as sr\n",
    "\n",
    "# # === Upload Handler ===\n",
    "# def explore_data(files):\n",
    "#     results = []\n",
    "#     if len(files) == 0:\n",
    "#         return \"Please upload at least one CSV file.\", \"\", \"\", \"\"\n",
    "\n",
    "#     for file in files:\n",
    "#         df = pd.read_csv(file.name)\n",
    "\n",
    "#         head = f\" `{file.name}`\\n\" + df.head().to_markdown()\n",
    "#         summary = df.describe().to_markdown()\n",
    "\n",
    "#         info_buf = io.StringIO()\n",
    "#         df.info(buf=info_buf)\n",
    "#         info = info_buf.getvalue()\n",
    "\n",
    "#         results.append((head, summary, info))\n",
    "\n",
    "#     all_preview = \"\\n\\n---\\n\\n\".join([r[0] for r in results])\n",
    "#     all_summary = \"\\n\\n---\\n\\n\".join([r[1] for r in results])\n",
    "#     all_info = \"\\n\\n---\\n\\n\".join([r[2] for r in results])\n",
    "\n",
    "#     return \"Upload successful!\", all_preview, all_summary, all_info\n",
    "\n",
    "# # === Chatbot with Basic Mode ===\n",
    "# def chatbot_response(message, history):\n",
    "#     response = process_query(message, mode=\"basic\")\n",
    "#     return response, history + [(message, response)]\n",
    "\n",
    "# # === Speech-to-Text ===\n",
    "# def speech_to_text(audio_file):\n",
    "#     recognizer = sr.Recognizer()\n",
    "#     with sr.AudioFile(audio_file) as source:\n",
    "#         audio_data = recognizer.record(source)\n",
    "#     try:\n",
    "#         return recognizer.recognize_google(audio_data)\n",
    "#     except sr.UnknownValueError:\n",
    "#         return \"Sorry, I couldn't understand that.\"\n",
    "\n",
    "# # === Insight Agent Mode ===\n",
    "# def launch_insight_agent(user_query, profile_summary, anomalies):\n",
    "#     if profile_summary is None or anomalies is None:\n",
    "#         profile_summary, anomalies = initialize_data_insights()\n",
    "\n",
    "#     response = process_query(user_query, mode=\"insight_agent\")\n",
    "#     return response, profile_summary, anomalies\n"
   ],
   "metadata": {
    "id": "SI-Y2O0CnZAs",
    "ExecuteTime": {
     "end_time": "2025-04-23T17:38:48.455310Z",
     "start_time": "2025-04-23T17:38:48.443568Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import io\n",
    "import speech_recognition as sr\n",
    "import globals\n",
    "from backend import process_query\n",
    "# === Upload Handler ===\n",
    "def explore_data(files):\n",
    "    results = []\n",
    "    if len(files) == 0:\n",
    "        return \"Please upload at least one CSV file.\", \"\", \"\", \"\", None\n",
    "\n",
    "    file = files[0]\n",
    "    globals.global_df = pd.read_csv(file.name)\n",
    "\n",
    "    head = f\" `{file.name}`\\n\" + globals.global_df.head().to_markdown()\n",
    "    summary = globals.global_df.describe().to_markdown()\n",
    "    agent_status=initialize_agent()\n",
    "    info_buf = io.StringIO()\n",
    "    globals.global_df.info(buf=info_buf)\n",
    "    info = info_buf.getvalue()\n",
    "    \n",
    "    return \"Upload successful!\", head, summary, info, globals.global_df\n",
    "\n",
    "\n",
    "def chatbot_response(message, history):\n",
    "    print(\"chatbot_response triggered with message:\", message)\n",
    "    response = process_query(message, mode=\"basic\")\n",
    "\n",
    "    if isinstance(response, tuple):  # EDA or image-generating response\n",
    "        message_text, plot_paths = response\n",
    "        updated_history = history + [(message, message_text)]\n",
    "        return updated_history, \"\", updated_history, plot_paths\n",
    "    else:\n",
    "        updated_history = history + [(message, response)]\n",
    "        return updated_history, \"\", updated_history, None\n",
    "\n",
    "\n",
    "\n",
    "def process_speech():\n",
    "    query = get_voice_input()  # Call the backend function\n",
    "    return query\n",
    "\n",
    "\n",
    "# === Speech-to-Text ===\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "    try:\n",
    "        return recognizer.recognize_google(audio_data)\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, I couldn't understand that.\"\n",
    "\n",
    "\n",
    "def launch_insight_agent(user_query, profile_summary, anomalies):\n",
    "    if profile_summary is None or anomalies is None:\n",
    "        profile_summary, anomalies = initialize_data_insights()\n",
    "\n",
    "    response = process_query(user_query, mode=\"insight_agent\")\n",
    "    return response, profile_summary, anomalies\n",
    "\n",
    "\n",
    "# === Gradio Interface ===\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 📊 Data Dashboard\")\n",
    "    gr.Markdown(\"### Explore, Clean & Analyze Your Data with AI\")\n",
    "\n",
    "    uploaded_data = gr.State(value=None)\n",
    "\n",
    "    with gr.Tab(\"📁 Upload + Explore\"):\n",
    "        file_input = gr.File(file_types=[\".csv\"], file_count=\"multiple\", label=\"Upload CSV files\")\n",
    "        status = gr.Textbox(label=\"Status\")\n",
    "        preview = gr.Markdown(label=\"Data Preview\")\n",
    "        summary = gr.Markdown(label=\"Summary Statistics\")\n",
    "        info = gr.Textbox(label=\"Data Info\", lines=15)\n",
    "\n",
    "        file_input.upload(\n",
    "            fn=explore_data,\n",
    "            inputs=file_input,\n",
    "            outputs=[status, preview, summary, info,uploaded_data]\n",
    "        )\n",
    "        format_select = gr.Radio([\"html\", \"pdf\"], label=\"Export Format\")\n",
    "\n",
    "        with gr.Row():\n",
    "          download_output = gr.File(label=\"Download Report\")\n",
    "          export_btn = gr.Button(\"Generate & Download Report\")\n",
    "\n",
    "        export_btn.click(\n",
    "        fn=handle_export_report,\n",
    "        inputs=[format_select],\n",
    "        outputs=[download_output])\n",
    "\n",
    "    with gr.Tab(\"💬 Chat with AI (Basic)\"):\n",
    "        gr.Markdown(\"Chat with your dataset (voice or text)\")\n",
    "\n",
    "        # transcript = gr.Textbox(label=\"Transcript\")\n",
    "        chat_history = gr.Chatbot(label=\"Chat\")\n",
    "        chat_gallery = gr.Gallery(label=\"📊 Visualizations\", show_label=True ,columns=3)\n",
    "        chat_input = gr.Textbox(label=\"Ask a question\")\n",
    "        chat_button = gr.Button(\"Send\")\n",
    "        chat_state = gr.State([])\n",
    "\n",
    "        chat_button.click(\n",
    "            fn=chatbot_response,\n",
    "            inputs=[chat_input, chat_state],\n",
    "            outputs=[chat_history, chat_input, chat_state,chat_gallery]\n",
    "        )\n",
    "\n",
    "        # Voice Input Button\n",
    "        voice_button = gr.Button(\"🎤 Speak your query\")\n",
    "        \n",
    "        def handle_voice_input():\n",
    "            return get_voice_input()\n",
    "\n",
    "        # Connect voice input to chat_input\n",
    "        voice_button.click(\n",
    "            fn=process_speech,\n",
    "            inputs=[],\n",
    "            outputs=chat_input\n",
    "        )\n",
    "\n",
    "\n",
    "    with gr.Tab(\"🧠 Data Insight Agent\"):\n",
    "        with gr.Row():\n",
    "            user_input = gr.Textbox(label=\"Ask a smart question about your dataset\")\n",
    "        with gr.Row():\n",
    "            output = gr.Textbox(label=\"Insight Response\", lines=20)\n",
    "        # Voice Input Button\n",
    "        voice_button = gr.Button(\"🎤 Speak your query\")\n",
    "\n",
    "        # Connect voice input to chat_input\n",
    "        voice_button.click(\n",
    "            fn=process_speech,\n",
    "            inputs=[],\n",
    "            outputs=chat_input\n",
    "        )\n",
    "\n",
    "        profile_summary = gr.State(value=None)\n",
    "        anomalies = gr.State(value=None)\n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "\n",
    "        submit_btn.click(\n",
    "            fn=launch_insight_agent,\n",
    "            inputs=[user_input, profile_summary, anomalies],\n",
    "            outputs=[output, profile_summary, anomalies]\n",
    "        )\n",
    "\n",
    "app.launch(server_name=\"127.0.0.1\", server_port=7867, debug=True)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "9BkntMkDnjOf",
    "outputId": "26a804ef-799b-4e47-d727-52a74bb5829f",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-23T17:47:07.078901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_8172\\2228978581.py:98: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat_history = gr.Chatbot(label=\"Chat\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:46:21.613504Z",
     "start_time": "2025-04-23T17:46:20.061628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "def handle_export_report(format: str):\n",
    "    # Create a temporary file path\n",
    "    ext = \"pdf\" if format.lower() == \"pdf\" else \"html\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{ext}\") as tmp_file:\n",
    "        output_path = tmp_file.name\n",
    "\n",
    "    try:\n",
    "        export_report(format=format, output_path=output_path)\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating report: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Gradio UI\n"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot call click outside of a gradio.Blocks context.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m     download_output = gr.File(label=\u001B[33m\"\u001B[39m\u001B[33mDownload Report\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     23\u001B[39m     export_btn = gr.Button(\u001B[33m\"\u001B[39m\u001B[33mGenerate & Download Report\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[43mexport_btn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mclick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhandle_export_report\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mformat_select\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdownload_output\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DataQuestHackathon\\insight_env\\Lib\\site-packages\\gradio\\events.py:662\u001B[39m, in \u001B[36mEventListener._setup.<locals>.event_trigger\u001B[39m\u001B[34m(block, fn, inputs, outputs, api_name, scroll_to_output, show_progress, show_progress_on, queue, batch, max_batch_size, preprocess, postprocess, cancels, trigger_mode, js, concurrency_limit, concurrency_id, show_api, time_limit, stream_every, like_user_message)\u001B[39m\n\u001B[32m    660\u001B[39m root_block = get_blocks_context()\n\u001B[32m    661\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m root_block \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m662\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m    663\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCannot call \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_event_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m outside of a gradio.Blocks context.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    664\u001B[39m     )\n\u001B[32m    666\u001B[39m event_target = EventListenerMethod(\n\u001B[32m    667\u001B[39m     block \u001B[38;5;28;01mif\u001B[39;00m _has_trigger \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, _event_name\n\u001B[32m    668\u001B[39m )\n\u001B[32m    670\u001B[39m dep, dep_index = root_block.set_event_trigger(\n\u001B[32m    671\u001B[39m     [event_target],\n\u001B[32m    672\u001B[39m     fn,\n\u001B[32m   (...)\u001B[39m\u001B[32m    701\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    702\u001B[39m )\n",
      "\u001B[31mAttributeError\u001B[39m: Cannot call click outside of a gradio.Blocks context."
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
